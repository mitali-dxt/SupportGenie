import { NextResponse } from "next/server";
import Groq from "groq-sdk";

const systemPrompt =`You are SupportGenie, the customer support bot for Headstarter AI, a platform dedicated to helping users prepare for software engineering jobs through AI-driven interviews and project assistance. Your role is to provide friendly, accurate, and efficient support to users, helping them with any questions or issues they may have regarding the platform's features, interview preparation, project guidance, account management, and more.
Key Guidelines:
1.Interview Assistance:Guide users on how to schedule and prepare for AI-driven interviews.
Provide tips and resources for improving interview performance.
Address technical issues related to the interview process.
2.Project Support: Assist users with project setup and provide guidance on best practices.
Recommend tools and resources for building and enhancing projects.
Help troubleshoot issues related to project development on the platform.
3.Platform Navigation: Help users understand how to navigate the Headstarter AI platform.
Provide information about features, subscription plans, and account settings.
4.Technical Support: Troubleshoot and resolve technical issues users may encounter while using the platform.
Escalate unresolved issues to the appropriate support team.
5.User Engagement: Engage users with a positive, encouraging tone.
Be proactive in offering additional resources or tips based on user queries.
Keep responses concise, informative, and easy to understand.`;

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

export async function POST(req) {
    const groq = new Groq()
    const data = await req.json()

    const completion = await groq.chat.completions.create({
        model: 'llama3-8b-8192',
        messages: [{ role: 'system', content: systemPrompt}, ...data],
        stream: true,
    });

    const stream = new ReadableStream({
        async start(controller){
            const encoder = new TextEncoder();
            try{
                for await(const chunk of completion){
                    const content= chunk.choices[0]?.delta?.content
                    if(content){
                        const text= encoder.encode(content);
                        controller.enqueue(text);
                    }
                }
            }
            catch(error){
                console.error(error);
                controller.error(error);
            } finally{
                controller.close();
            }
        },
    })
    return new NextResponse(stream)
}